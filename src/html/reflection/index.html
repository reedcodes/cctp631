<!doctype html>
<html>

<partial src="head.html" title="Final Reflection"></partial>

<body>

  <header>
    <partial src="header.html" title="Final Reflection" date="13 May 2021"></partial>
  </header>

  <main>

    <figure class="hero">
      <img src="/cctp631/dist/images/typewriter.jpg" alt="A typewriter with a piece of paper rolled through its carriage. The words FAKE NEWS are typed on the paper." />
      <figcaption>
        <i>Figure 1.</i> “Fake News” (Franganillo).
      </figcaption>
    </figure>

    <h1>
      <span class="fa-fw fas fa-question-circle" aria-hidden="true"></span>
      <span>Problematic content</span>
    </h1>

    <p>Over the past few years, there has been much discussion about “fake news” and the spread of “problematically inaccurate information” (Jack 1) online and in the media. The difference in problematic content lies in its intent.</p>

    <div class="full">
      <div class="compare">
        <p><strong>Misinformation</strong> is information that is incorrect or inaccurate but <em>unintentionally</em> so (2).</p>
        <p><strong>Disinformation</strong> is <em>purposeful</em> in its inaccuracy and is often created to deceive or cause confusion (3).</p>
      </div>
    </div>

    <p>However, regardless of intent, dis- or misinformation is problematic because it has the potential to cause physical, emotional, political, and financial harm to individuals, communities, and society. This was witnessed most recently (at the time of this writing) with the 2020 elections and the COVID-19 pandemic.</p>

    <h1>
      <span class="fa-fw fas fa-redo-alt" aria-hidden="true"></span>
      <span>Over and over and over...</span>
    </h1>

    <p>When a piece of information is frequently and consistently repeated, the more people tend to believe it; this is the case whether someone is hearing dis- or misinformation that is clearly false, or if they are hearing news that is a denial or a debunking of dis- or misinformation (Clark; Illling; Lewandowsky; Nyhan and Reifler). For instance, repeated exposure to misinformation about COVID-19 led to people drinking bleach in an effort to kill the virus, or demanding prescriptions for hydroxychloroquine from their doctors (Satariano). Those who stormed the Capitol on January 6, 2021 did so because they believed that there was widespread voter fraud during the 2020 election cycle, that Donald Trump had truly won the presidential vote, and that democracy was under attack (Bond; Rash); they believed this because these “continuous assertions” (Rash) were repeated frequently by then-President Trump and his followers.</p>

    <p>When people hear repeated information, it gets stuck in their minds, and it then becomes difficult for them to believe the truth when confronted with it. This is not limited to social media, and it is not a new phenomena; in the 1940s, it took an investigation by the FBI to formally disprove the existence of secret grassroot “Eleanor Clubs” that were purported to have organized Black women, yet many newspapers refused to believe it or publish retractions (Zeitz).</p>

    <p>Nyhan and Reifler recommend that journalists “get the story right the first time” and that if corrections are needed, to publish them as soon as possible, to avoid negations, and to keep repetition to a minimum.</p>

    <h1>
      <span class="fa-fw fas fa-comment-dots" aria-hidden="true"></span>
      <span>Read it, believe it, share it</span>
    </h1>

    <p>Although misinformation is a problem on social media platforms, the number of people sharing dis- and misinformation and “fake news” is not as high as formerly suspected, and the small percentage of people sharing accounts for the greatest percentage of misinformation (Altay et al.; Guess et al.). Altay et al. asserts that people hope to maintain their reputations, and spreading false information could damage their credibility, especially as trust is slow to earn, but quick to lose (3). However, things get a little more complicated when the intent is not to trick or fool anyone, and social media users are taking in by convincing content.</p>

    <figure class="hero">
      <img src="/cctp631/dist/images/misinfo-matrix.jpg" aria-hidden="true" />

      <table class="visually-hidden">
        <caption>Misinformation Matrix</caption>
        <thead>
          <tr>
            <th scope="col">Type of Motivation</th>
            <th scope="col">Satire or Parody</th>
            <th scope="col">False Connection</th>
            <th scope="col">Misleading Content</th>
            <th scope="col">False Context</th>
            <th scope="col">Imposter Content</th>
            <th scope="col">Manipulated Content</th>
            <th scope="col">Fabricated Content</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <th scope="row">Poor Journalism</th>
            <td>no</td>
            <td>yes</td>
            <td>yes</td>
            <td>yes</td>
            <td>no</td>
            <td>no</td>
            <td>no</td>
          </tr>
          <tr>
            <th scope="row">To Parody</th>
            <td>yes</td>
            <td>no</td>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>no</td>
            <td>yes</td>
          </tr>
          <tr>
            <th scope="row">To Provoke or to Punk</th>
            <td>no</td>
            <td>no</td>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>yes</td>
            <td>yes</td>
          </tr>
          <tr>
            <th scope="row">Passion</th>
            <td>no</td>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>no</td>
            <td>no</td>
            <td>no</td>
          </tr>
          <tr>
            <th scope="row">Partisanship</th>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>yes</td>
            <td>no</td>
            <td>no</td>
            <td>no</td>
          </tr>
          <tr>
            <th scope="row">Profit</th>
            <td>no</td>
            <td>yes</td>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>no</td>
            <td>yes</td>
          </tr>
          <tr>
            <th scope="row">Political Influence</th>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>yes</td>
            <td>no</td>
            <td>yes</td>
            <td>yes</td>
          </tr>
          <tr>
            <th scope="row">Propaganda</th>
            <td>no</td>
            <td>no</td>
            <td>yes</td>
            <td>yes</td>
            <td>yes</td>
            <td>yes</td>
            <td>yes</td>
          </tr>
        </tbody>
      </table>
      <figcaption>
        <i>Figure 2.</i> A “misinformation matrix” of the different types of problematic content, along the header row, compared to motivations for its creation, along the header column (Wardle).
      </figcaption>
    </figure>

    <p>Satire or parody is on the low end of the intent-to-deceive scale, with humor as its main motivation to spoof or mock its target, although it still may have potential to deceive (Wardle). While Allcott and Gentzkow rule out satire in their definition of “fake news” (214), a study from Garrett et al. found that some people cannot differentiate between news stories and satirical posts, using articles from <i>The Babylon Bee</i> and <i>The Onion</i>, two popular satire websites. One of their suggestions is to clearly label these articles as satire when they are posted to social media or pulled up in search results, although Scott Dikkers, founder of <i>The Onion</i>, and many long-time readers of <i>The Onion</i> take offense that people cannot tell the difference between real news, “fake news”, and the stories posted on satirical websites (Hutchison).</p>

    <p>Further, even Facebook’s own moderators and algorithms can sometimes get it wrong. A “honeypot” group called Vaccines Exposed, whose members debated anti-vaxxers in an effort to change their minds, was removed from the platform in January 2021 (Rogers). Matt Saincome, co-founder of The Hard Times, a satirical music website, posted on Twitter in March 2021 asking for help in appealing Facebook’s decision to remove some of their posts for violating community standards and to potentially remove their page from the platform completely.</p>

    <h1>
      <span class="fa-fw fas fa-poop" aria-hidden="true"></span>
      <span>Wading through all the muck</span>
    </h1>

    <p>As recently as March 2021 (at the time of this writing), heads of major social media and tech companies testified about misinformation, its proliferation on their platforms, and the possible solutions for mitigating its spread (Bond).</p>

    <p>It’s important to attack the problem on a systemic level and to focus on how misinformation is spread, and to not blame any specific individuals, which can intensify stigma, further isolate communities, and deepen susceptibility for believing misinformation (Gynes and Mina). Having research, citation, and media literacy skills are helpful, but they are the first step, not the only step (boyd). Caulfield proposes a short list of “things to do” when examining a source (“SIFT”):</p>

    <figure class="hero">
      <img src="/cctp631/dist/images/sift-infographic.png" alt="1) Stop. 2) Investigate the source. 3) Find better coverage. 4) Trace claims, quotes, and media to the original context." />
      <figcaption>
        <i>Figure 3.</i> Caulfield’s four moves (“SIFT”).
      </figcaption>
    </figure>

    <p>These moves come at a time when new techniques are needed for research and analysis. While older techniques do have their place, they do not take into account the changes in today’s modern technologies, such as the massive amount of information available on the internet, including the validity of websites like Wikipedia (boyd; Caulfield, “Yes, Digital Literacy”; Caulfield, “SIFT”). In addition to understanding how to check the currency, authority, purpose, or bias of a source, people also need the skills in how to catch other clues, such as political bias, white supremecist ideology, or straight up manufactured details (Caulfield, “Yes, Digital Literacy). As mentioned above, once someone knows that <i>The Onion</i> publishes satirical news, they are at a very low risk for spreading that information as if it were real.</p>

    <h1>
      <span class="fa-fw fas fa-thumbs-up" aria-hidden="true"></span>
      <span>Responsible solutions for everyone</span>
    </h1>

    <p>Many social media companies already have policies in place to deal with misinformation on their platforms; some of these practices include labeling content as misleading or disputed, removing content, banning users, adding prompts before sharing, and allowing users to report content or other users (Mozilla Foundation). However, many political figures contend that this is not enough. This past March (at the time of this writing), heads of major social media and tech companies testified via video before Congress about misinformation, its proliferation on their platforms, and the possible solutions for mitigating its spread (Bond). Several representatives have called to reform or even repeal Section 230 of the Communications Decency Act, which states:</p>

    <blockquote>
      <p>No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.</p>
      <cite>(United States Code)</cite>
    </blockquote>

    <p>With Section 230, social media companies are free from liability for what their users post on their platforms, but if they do not address the systemic issues of dis- and misinformation (including hate speech) on their platforms, it sends the message that targeted groups are “second class citizens” (Citron and Norton, qtd. in Piernock 9). Yet, repealing Section 230 completely could have “unintended consequences” (Pichai qtd. in Bond) as some sites may over-moderate their content, or some may not be able to host user-generated content at all due to the burden of moderation. On the other hand, these platforms can build content moderation guidelines, using Section 230 as a tool and Lessig’s four forces of regulation to help mitigate misinformation spread (Piernock 12). Some examples may include:</p>

    <ul>
      <li>platforms providing clearer methods for users to report or assert that content is misinformation or is unacceptable;</li>
      <li>platforms and users debunking misinformation when possible;</li>
      <li>platforms incorporating overlays or labels to misleading or deceptive content; and</li>
      <li>platforms providing greater transparency in moderation guidelines.</li>
    </ul>

    <p>Saltz et al. provide multiple design techniques for labeling misinformation on social media platforms. Based on solid usability and user experience principles, these techniques could promote digital literacy by clearly labeling content and also presenting new approaches to deciphering the various clues of misinformation.</p>
  </main>

  <footer>
    <h1>
      <span class="fa-fw fas fa-clipboard" aria-hidden="true"></span>
      <span>Addendum</span>
    </h1>

    <h2>Colophon</h2>
    <partial src="colophon.html"></partial>

    <h1>
      <span class="fa-fw fas fa-book" aria-hidden="true"></span>
      <span>References</span>
    </h1>

    <h2>Works Cited</h2>
    <ul>
      <li>@MattSaincome. “Facebook is threatening to delete The Hard Times. [...]” Twitter, 13 May 2021, <a href="https://twitter.com/MattSaincome/status/1392985067488567296">twitter.com/MattSaincome/status/1392985067488567296</a>. Accessed 13 May 2021.</li>
      <li>Allcott, Hunt and Matthew Gentzkow. “Social Media and Fake News in the 2016 Election.” <i>Journal of Economic Perspectives</i>, vol. 31, no. 2, 2017, pp. 211-236, <a href="https://doi.org/10.1257/jep.31.2.211">doi:10.1257/jep.31.2.211</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 10 Feb 2021.</li>
      <li>Altay, Sacha et al. “Why Do So Few People Share Fake News? It Hurts Their Reputation.” <i>New Media & Society</i>, Nov 2020, pp. 1-22, <a href="https://doi.org/10.1177/1461444820969893">doi:10.1177/1461444820969893</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 10 Mar 2021.</li>
      <li>Bond, Shannon. "Facebook, Twitter, Google CEOs Testify Before Congress: 4 Things To Know." <i>Untangling Disinformation</i>, 25 Mar 2021, <a href="https://npr.org/2021/03/25/980510388/facebook-twitter-google-ceos-testify-before-congress-4-things-to-know">npr.org/2021/03/25/980510388/facebook-twitter-google-ceos-testify-before-congress-4-things-to-know</a>. <i>NPR</i>. Accessed 13 May 2021.</li>
      <li>boyd, danah. “Did Media Literacy Backfire?” <i>Data & Society: Points</i>, 16 Mar 2018, <a href="https://points.datasociety.net/did-media-literacy-backfire-7418c084d88d">points.datasociety.net/did-media-literacy-backfire-7418c084d88d</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 13 Apr 2021.</li>
      <li>Caulfield, Mike. “SIFT: The Four Moves.” <i>Hapgood</i>, 19 Jun 2019, <a href="https://hapgood.us/2019/06/19/sift-the-four-moves/">hapgood.us/2019/06/19/sift-the-four-moves/</a>. Accessed 15 May 2021.</li>
      <li>Caulfield, Mike. “Yes, Digital Literacy. But Which One?” <i>Hapgood</i>, 19 Dec 2016, <a href="https://hapgood.us/2016/12/19/yes-digital-literacy-but-which-one/">hapgood.us/2016/12/19/yes-digital-literacy-but-which-one/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 13 Apr 2021.</li>
      <li>Clark, Taylor. “The 8 ½ Laws of Rumor Spread.” <i>Psychology Today</i>, 9 Jun 2016, <a href="https://psychologytoday.com/us/articles/200811/the-8-laws-rumor-spread">psychologytoday.com/us/articles/200811/the-8-laws-rumor-spread</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 23 Feb 2021.</li>
      <li>Franganillo, Jorge. "Fake News." <i>Flickr</i>, 16 Apr 2021, <a href="https://flickr.com/photos/franganillo/51120419628/">flickr.com/photos/franganillo/51120419628/</a>. Accessed 13 May 2021.</li>
      <li>Garrett, R. Kelly et al. “Too Many People Think Satirical News is Real.” <i>The Conversation</i>, 16 Aug 2019, <a href="https://theconversation.com/too-many-people-think-satirical-news-is-real-121666">theconversation.com/too-many-people-think-satirical-news-is-real-121666</a>. Accessed 15 May 2021.</li>
      <li>Guess, Andrew et al. “Less Than You Think: Prevalence and Predictors of Fake News Dissemination on Facebook.” <i>Science Advances</i>, vol. 5, no. 1, 9 Jan 2019, pp. 1-8, <a href="https://doi.org/10.1126/sciadv.aau4586">doi:10.1126/sciadv.aau4586</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 9 Mar 2021.</li>
      <li>Gyenes, Nat and An Xiao Mina. “How Misinfodemics Spread Disease.” <i>The Atlantic</i>, 30 Aug 2018, <a href="https://theatlantic.com/technology/archive/2018/08/how-misinfodemics-spread-disease/568921/">theatlantic.com/technology/archive/2018/08/how-misinfodemics-spread-disease/568921/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 4 Apr 2021.</li>
      <li>Hutchinson, Ben. “‘The Onion’ Founder: We Do Satire, Not Fake News.” <i>WISN 12-Milwaukee</i>, 15 Feb 2017, <a href="https://wisn.com/article/the-onion-founder-we-do-satire-not-fake-news/8940879">wisn.com/article/the-onion-founder-we-do-satire-not-fake-news/8940879</a>. Accessed 14 May 2021.</li>
      <li>Illing, Sean. “‘Flood the Zone with Shit’: How Misinformation Overwhelmed Our Democracy.” <i>Vox</i>, 16 Jan 2020, <a href="https://www.vox.com/platform/amp/policy-and-politics/2020/1/16/20991816/impeachment-trial-trump-bannon-misinformation">vox.com/platform/amp/policy-and-politics/2020/1/16/20991816/impeachment-trial-trump-bannon-misinformation</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 24 Mar 2021.</li>
      <li>Jack, Caroline. <i>Lexicon of Lies: Terms for Problematic Information</i>, <a href="https://datasociety.net/library/lexicon-of-lies/">datasociety.net/library/lexicon-of-lies/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 28 Jan 2021.</li>
      <li>Lewandowsky, Stephan. <i>The Debunking Handbook 2020</i>, <a href="https://doi.org/10.17910/b7.1182">doi:10.17910/b7.1182</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 19 Apr 2021.</li>
      <li>Mozilla Foundation. “US Election 2020: Platform Misinformation Policies Tracker.” 21 Jan 2021, <a href="https://foundation.mozilla.org/en/campaigns/election-policy-tracker/">foundation.mozilla.org/en/campaigns/election-policy-tracker/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 16 Apr 2021.</li>
      <li>Nyhan, Brendan and Jason Reifler. “Countering Misinformation: Tips for Journalists.” <i>Columbia Journalism Review</i>, 29 Feb 2012, <a href="https://archives.cjr.org/united_states_project/_countering_misinformation_tip.php">archives.cjr.org/united_states_project/_countering_misinformation_tip.php</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 16 Mar 2021.</li>
      <li>Piernock, Reed. “‘N—rs Can’t Do Cosplay’: Addressing Online Hate Speech Targeted at Black Women in Nerd Communities.” 20 Jan 2020. CCTP-591, Georgetown University, unpublished student paper.</li>
      <li>Rash, Wayne. “Disinformation Propelled by Social Media and Conspiracy Theories Led to Insurrection.” <i>Forbes</i>, 19 Jan 2021, <a href="https://forbes.com/sites/waynerash/2021/01/19/disinformation-propelled-by-social-media-and-conspiracy-theories-led-to-insurrection/">forbes.com/sites/waynerash/2021/01/19/disinformation-propelled-by-social-media-and-conspiracy-theories-led-to-insurrection/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 1 Feb 2021.</li>
      <li>Rogers, Kaleigh. “Why Fights Over the COVID-19 Vaccine are Everywhere on Facebook.” <i>FiveThirtyEight</i>, 22 Jan 2021, <a href="https://fivethirtyeight.com/features/why-fights-over-the-covid-19-vaccine-are-everywhere-on-facebook/">fivethirtyeight.com/features/why-fights-over-the-covid-19-vaccine-are-everywhere-on-facebook/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 4 Apr 2021.</li>
      <li>Saltz, Emily et al. “It Matters How Platforms Label Manipulated Media. Here are 12 Principles Designers Should Follow.” <i>First Draft News</i>, 10 Jun 2020, <a href="https://firstdraftnews.org/latest/it-matters-how-platforms-label-manipulated-media-here-are-12-principles-designers-should-follow/">firstdraftnews.org/latest/it-matters-how-platforms-label-manipulated-media-here-are-12-principles-designers-should-follow/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 28 Apr 2021.</li>
      <li>Satariano, Adam. "Coronavirus Doctors Battle another Scourge: Misinformation." <i>New York Times</i>, Aug 17, 2020. <i>ProQuest</i>, <a href="https://www-proquest-com.proxy.library.georgetown.edu/newspapers/coronavirus-doctors-battle-another-scourge/docview/2434574019/se-2?accountid=11091">www-proquest-com.proxy.library.georgetown.edu/newspapers/coronavirus-doctors-battle-another-scourge/docview/2434574019/se-2?accountid=11091</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 2 Feb 2021.</li>
      <li>United States Code. Title 47, section 230. ​Legal Information Institute​, Cornell Law School. <a href="https://law.cornell.edu/uscode/text/47/230">law.cornell.edu/uscode/text/47/230</a>. Accessed 14 May 2021.</li>
      <li>Wardle, Claire. “Fake News: It’s Complicated.” <i>First Draft News</i>, 16 Feb 2017, <a href="https://firstdraftnews.org/latest/fake-news-complicated/">firstdraftnews.org/latest/fake-news-complicated/</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 2 Feb 2021.</li>
      <li>Zeitz, Joshua. “Lessons from the Fake News Pandemic of 1942.” <i>Politico</i>, 12 Mar 2017, <a href="https://politico.com/magazine/story/2017/03/lessons-from-the-fake-news-pandemic-of-1942-214898">politico.com/magazine/story/2017/03/lessons-from-the-fake-news-pandemic-of-1942-214898</a>. <i>Canvas</i>, uploaded by Leticia Bode, 2021, <a href="https://georgetown.instructure.com/">georgetown.instructure.com</a>. Accessed 9 Feb 2021.</li>
    </ul>
  </footer>

<partial src="scripts.html"></partial>

</body>
</html>
